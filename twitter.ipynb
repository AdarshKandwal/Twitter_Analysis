{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355063556987871232\n",
      "1355063557629460485\n",
      "1355063561047961602\n",
      "1355063564839489537\n",
      "1355063587258073088\n",
      "1355063734507499523\n",
      "1355063765369188355\n",
      "1355063828850102273\n",
      "1355063848659800064\n",
      "1355063887574392834\n",
      "1355063896294510592\n",
      "1355063918910009344\n",
      "1355063937826508802\n",
      "1355063975101296649\n",
      "1355064032965898241\n",
      "1355064110556327938\n",
      "1355064296036855808\n",
      "1355064388877746176\n",
      "1355064553080573955\n",
      "1355064556326969346\n",
      "1355064560089227271\n",
      "1355064579039105024\n",
      "1355064579944894468\n",
      "1355064587683467275\n",
      "1355064600882909186\n",
      "1355064677194223621\n",
      "1355064799667892231\n",
      "1355064800682905601\n",
      "1355064806764548099\n",
      "1355064807720767499\n",
      "1355064809713111042\n",
      "1355064816218435584\n",
      "1355064916693147650\n",
      "1355065000163897344\n",
      "1355065007566848004\n",
      "1355065010024833025\n",
      "1355065016341458946\n",
      "1355065023698186242\n",
      "1355065043080126464\n",
      "1355065145911730178\n",
      "1355065229181386752\n",
      "1355065250593304576\n",
      "1355065276757323776\n",
      "1355065301101109249\n",
      "1355065320613031938\n",
      "1355065325247627264\n",
      "1355065399260286978\n",
      "1355065420974186501\n",
      "1355065425525149696\n",
      "1355065453111111681\n",
      "1355065453828333570\n",
      "1355065458450460672\n",
      "1355065471372988417\n",
      "1355065518265225216\n",
      "1355065567330377729\n",
      "1355065723421220871\n",
      "1355065734825697281\n",
      "1355065740035043330\n",
      "1355065749128302598\n",
      "1355065820431446018\n",
      "1355065845672800258\n",
      "1355065871635386369\n",
      "1355065890681860096\n",
      "1355065901297532929\n",
      "1355065910864834561\n",
      "1355065913137979392\n",
      "1355066022861144064\n",
      "1355066104729624585\n",
      "1355066135776002048\n",
      "1355066186661326849\n",
      "1355066191325265923\n",
      "1355066242474729475\n",
      "1355066312410583043\n",
      "1355066321424314372\n",
      "1355066386268049408\n",
      "1355066455478267907\n",
      "1355066463145652228\n",
      "1355066467084021760\n",
      "1355066491071307776\n",
      "1355066532976594948\n",
      "1355066543122612224\n",
      "1355066650798657542\n",
      "1355066762744758275\n",
      "1355066778662150144\n",
      "1355066835654197249\n",
      "1355066844344942593\n",
      "1355066855992430593\n",
      "1355066864876072960\n",
      "1355066970501042178\n",
      "1355066971235123202\n",
      "1355066974825447424\n",
      "1355066990914768896\n",
      "1355066993720782849\n",
      "1355067000092024832\n",
      "1355067082363179012\n",
      "1355067165548769283\n",
      "1355067418943643649\n",
      "1355067419560189952\n",
      "1355067498576547840\n",
      "1355067525994672128\n",
      "1355067534836445184\n",
      "1355067540976889856\n",
      "1355067570722918400\n",
      "1355067628587520001\n",
      "1355067652020944897\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'out.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-792e2e5e6512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"date,user,is_retweet,is_quote,text,quoted_text\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"hate speech\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, raw_data)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'in_reply_to_status_id'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'delete'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-792e2e5e6512>\u001b[0m in \u001b[0;36mon_status\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mquoted_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"out.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s,%s,%s,%s,%s,%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_retweet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_quote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquoted_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'out.csv'"
     ]
    }
   ],
   "source": [
    "import tweepy,sys\n",
    "\n",
    "# authorization tokens\n",
    "consumer_key = \"OCDB6LkvMP4LbSC38nr7YL3wm\"\n",
    "consumer_secret = \"7oiFUQWMRQi1jPLaMxWrUwTWgrs7BEmk5ASRL0o3V3D3Pkgk63\"\n",
    "access_key = \"1352243251944726531-ckBNYHjFukiGa6IjFYD5pvhR4JYOaS\"\n",
    "access_secret = \"QWnuznNHQC8N5Y7QxFPriQYMbb2Nq6mXpzUUUeAHVXO0n\"\n",
    "\n",
    "# StreamListener class inherits from tweepy.StreamListener and overrides on_status/on_error methods.\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print(status.id_str)\n",
    "        # if \"retweeted_status\" attribute exists, flag this tweet as a retweet.\n",
    "        is_retweet = hasattr(status, \"retweeted_status\")\n",
    "\n",
    "        # check if text has been truncated\n",
    "        if hasattr(status,\"extended_tweet\"):\n",
    "            text = status.extended_tweet[\"full_text\"]\n",
    "        else:\n",
    "            text = status.text\n",
    "\n",
    "        # check if this is a quote tweet.\n",
    "        is_quote = hasattr(status, \"quoted_status\")\n",
    "        quoted_text = \"\"\n",
    "        if is_quote:\n",
    "            # check if quoted tweet's text has been truncated before recording it\n",
    "            if hasattr(status.quoted_status,\"extended_tweet\"):\n",
    "                quoted_text = status.quoted_status.extended_tweet[\"full_text\"]\n",
    "            else:\n",
    "                quoted_text = status.quoted_status.text\n",
    "\n",
    "        # remove characters that might cause problems with csv encoding\n",
    "        remove_characters = [\",\",\"\\n\"]\n",
    "        for c in remove_characters:\n",
    "            text.replace(c,\" \")\n",
    "            quoted_text.replace(c, \" \")\n",
    "\n",
    "        with open(\"out.csv\", \"a\", encoding='utf-8') as f:\n",
    "            f.write(\"%s,%s,%s,%s,%s,%s\\n\" % (status.created_at,status.user.screen_name,is_retweet,is_quote,text,quoted_text))\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Encountered streaming error (\", status_code, \")\")\n",
    "        sys.exit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # complete authorization and initialize API endpoint\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # initialize stream\n",
    "    streamListener = StreamListener()\n",
    "    stream = tweepy.Stream(auth=api.auth, listener=streamListener,tweet_mode='extended')\n",
    "    with open(\"out.csv\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(\"date,user,is_retweet,is_quote,text,quoted_text\\n\")\n",
    "    tags = [\"hate speech\"]\n",
    "    stream.filter(track=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6: expected 6 fields, saw 9\\nSkipping line 9: expected 6 fields, saw 7\\nSkipping line 25: expected 6 fields, saw 8\\nSkipping line 26: expected 6 fields, saw 7\\nSkipping line 34: expected 6 fields, saw 7\\nSkipping line 35: expected 6 fields, saw 7\\nSkipping line 37: expected 6 fields, saw 9\\nSkipping line 38: expected 6 fields, saw 9\\nSkipping line 39: expected 6 fields, saw 8\\nSkipping line 43: expected 6 fields, saw 7\\nSkipping line 58: expected 6 fields, saw 8\\nSkipping line 67: expected 6 fields, saw 9\\nSkipping line 68: expected 6 fields, saw 7\\nSkipping line 69: expected 6 fields, saw 8\\nSkipping line 70: expected 6 fields, saw 8\\nSkipping line 106: expected 6 fields, saw 10\\nSkipping line 109: expected 6 fields, saw 10\\nSkipping line 110: expected 6 fields, saw 7\\nSkipping line 122: expected 6 fields, saw 9\\nSkipping line 126: expected 6 fields, saw 7\\nSkipping line 133: expected 6 fields, saw 10\\nSkipping line 143: expected 6 fields, saw 8\\nSkipping line 146: expected 6 fields, saw 7\\nSkipping line 150: expected 6 fields, saw 7\\nSkipping line 160: expected 6 fields, saw 8\\nSkipping line 162: expected 6 fields, saw 7\\nSkipping line 164: expected 6 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('out.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @alexfeinberg1: You really thought \"Hate Speech\" was about protecting the vulnerable didn't you?\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @pegobry: I did not have \"Short squeezes are declared hate speech\" on my 2021 bingo card.\n",
      "Just report for hate speech\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @wokal_distance: 1/\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @LozzaFox: \"The people the Duke and Duchess of Sussex are funding are hard-left political activists who want to censor anyone who challe…\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "Official source say this is wrong.\n",
      "anyway.. I should probably delete.. it's just hate speech at this point.. unconstructive.. \n",
      "RT @PrisonPlanet: The #GameStop saga has taught us that \"hate speech\" is just an excuse for technocratic elites to silence &amp; blockade their…\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "@GraceSm94145617 @rkymtniww @laurenboebert Well that depends what you use free speech to say. If you use it to commit an act of hate crime\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @syahredzan: Just report for hate speech\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "@AlianisBgd @yuliansahap Ini hate.speech\n",
      "RT @wokal_distance: 1/\n",
      "RT @BDSmovement: Israel is asking @Facebook to add the word “Zionist” to its hate speech policy.\n",
      "@IsmailSabri60 Ramai² report hate speech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @Progrockfarmer: \"Epstein killed himself\"\n",
      " a spokesperson for Discord tells me. \"To be clear\n",
      "Quel discours de haine ?\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @RirryVLNY: kamu hobi menebar hate speech gt kalo gajadi buzzer politik ya rugi toh sebenere\n",
      "@NBCNews Posted... \n",
      "RT @hpmacd: Discord shutting down WSB server for “hate speech” after trading hours (i.e. when institutional investors have a huge advantage…\n",
      "ไม่สร้างความเกลียดชังเลย 55555 เอาจริงๆถ้าจะให้ทำคอนเทนต์ Hate Speech จริง กูทำได้ดีกว่ามึงเยอะ แต่สื่อเขาไม่ทำกันเพราะยังมีความเป็นคนอยู่ไง ไอ้สื่อลิ้มเลียหีปลาโลมา จาบจ้วงประชาชนเลียไข่พ่อมัน\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PrisonPlanet: The #GameStop saga has taught us that \"hate speech\" is just an excuse for technocratic elites to silence &amp; blockade their…\n",
      "RT @zeaxumawit: How does @YouTube delete a short clip of Daniel Kibret's speech for hate speech but still host the full video on @adebabyMe…\n",
      "RT @lhfang: Bernie challenging Hillary for the presidential nomination? That's hate speech. Protesting Israel on campus? That's hate speech…\n",
      "🤦🏾‍♂️\n",
      "RT @Bhakti_Varak: Dear @priyankac19 and @OfficeofUT is this the ideology of your party @ShivSena and does it stand for your workers openly…\n",
      "RT @Bhakti_Varak: Dear @priyankac19 and @OfficeofUT is this the ideology of your party @ShivSena and does it stand for your workers openly…\n",
      "RT @90sgirl56: Aamir sir last speech 🥺 Zafar is the villian we can never hate Zafar naam yaad rahega🥺🥺 \n",
      "RT @wokal_distance: 1/\n",
      "RT @DailyCaller: REPORT: Oversight Board For Facebook Reverses Censorship After Allegedly Labeling Content ‘Hate Speech’ And ‘Misinformatio…\n",
      "@Tina_Hokwana Can a person be anti homosexuality without them discriminating against their rights?\n",
      "RT @90sgirl56: Aamir sir last speech 🥺 Zafar is the villian we can never hate Zafar naam yaad rahega🥺🥺 \n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "Facebook Ireland campaign to target hate speech on platform https://t.co/qCWQc6kvAO\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "Facebook Ireland launches campaign to tackle hate speech on their platform https://t.co/nLyTzEwWAP\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @wokal_distance: 1/\n",
      "RT @PrisonPlanet: The #GameStop saga has taught us that \"hate speech\" is just an excuse for technocratic elites to silence &amp; blockade their…\n",
      "RT @HeerSaleti_: -170+ farmers died\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "@vlada_janjanin @UspehPetrovic @Jachim992 Pa...ugasili su im discord server \n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @Liv_Boeree: “it will change nothing” they said\n",
      "RT @izzygirl86: No se podía saber que el engendro del hate speech no era más que una herramienta de control de masas a utilizar a discreció…\n",
      "RT @LozzaFox: \"The people the Duke and Duchess of Sussex are funding are hard-left political activists who want to censor anyone who challe…\n",
      "Done report hate speech. Disgusting white hair old man.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @HeerSaleti_: -170+ farmers died\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "There trying but something something \"hate speech\" has them banned....🤡🌍🤷‍♂️\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "RT @lhfang: Bernie challenging Hillary for the presidential nomination? That's hate speech. Protesting Israel on campus? That's hate speech…\n",
      "RT @HusinShihab: Doakan semoga lancar hari ini kita sidang kasus @syahganda salah satu deklarator KAMI terkait dugaan berita bohong dan hat…\n",
      "RT @SEDLAW15: This incredible language is from one of the decisions released from Facebook's Oversight Administration Board today. This cas…\n",
      "# Jack Dorsie\n",
      "Done report hate speech jugek\n",
      "RT @PrisonPlanet: The #GameStop saga has taught us that \"hate speech\" is just an excuse for technocratic elites to silence &amp; blockade their…\n",
      "RT @ggreenwald: This is the template created to demonize and silence anyone challenging elites. It was used against Bernie supporters (\"har…\n",
      "@AOC AOC your hate speech is dividing America and you really have the perspective of a 13 year old throwing a temper tantrum.  Enjoy the like light while it lasts.\n",
      "RT @PoliticalShort: Soon \"the market is rigged\" will be deemed hate speech by Big Tech.\n",
      "Wall St: \"Game Stop is going to burn because of the pandemic so we will short more than 130% of the stock.\"\n"
     ]
    }
   ],
   "source": [
    "for i in text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = np.array(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_se)\n",
    "word_index=tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'rt': 2,\n",
       " 'hate': 3,\n",
       " 'speech': 4,\n",
       " 'the': 5,\n",
       " 'is': 6,\n",
       " 'will': 7,\n",
       " 'be': 8,\n",
       " 'politicalshort': 9,\n",
       " 'soon': 10,\n",
       " 'market': 11,\n",
       " 'rigged': 12,\n",
       " 'deemed': 13,\n",
       " 'by': 14,\n",
       " 'big': 15,\n",
       " 'tech': 16,\n",
       " 'to': 17,\n",
       " 'for': 18,\n",
       " 'of': 19,\n",
       " 'and': 20,\n",
       " 'a': 21,\n",
       " 'just': 22,\n",
       " 'this': 23,\n",
       " 'report': 24,\n",
       " 'you': 25,\n",
       " 'are': 26,\n",
       " 'on': 27,\n",
       " 'has': 28,\n",
       " 'that': 29,\n",
       " 'an': 30,\n",
       " 'elites': 31,\n",
       " 'silence': 32,\n",
       " 'it': 33,\n",
       " 'your': 34,\n",
       " 'wokal': 35,\n",
       " 'distance': 36,\n",
       " '1': 37,\n",
       " 'who': 38,\n",
       " 'prisonplanet': 39,\n",
       " 'gamestop': 40,\n",
       " 'saga': 41,\n",
       " 'taught': 42,\n",
       " 'us': 43,\n",
       " 'excuse': 44,\n",
       " 'technocratic': 45,\n",
       " 'amp': 46,\n",
       " 'blockade': 47,\n",
       " 'their…': 48,\n",
       " 'facebook': 49,\n",
       " \"that's\": 50,\n",
       " 'zafar': 51,\n",
       " 'i': 52,\n",
       " 'have': 53,\n",
       " 'short': 54,\n",
       " 'anyone': 55,\n",
       " 'israel': 56,\n",
       " 'discord': 57,\n",
       " 'de': 58,\n",
       " 'does': 59,\n",
       " 'bernie': 60,\n",
       " 'challenging': 61,\n",
       " 'we': 62,\n",
       " 'can': 63,\n",
       " 'really': 64,\n",
       " 'was': 65,\n",
       " 'lozzafox': 66,\n",
       " 'people': 67,\n",
       " 'duke': 68,\n",
       " 'duchess': 69,\n",
       " 'sussex': 70,\n",
       " 'funding': 71,\n",
       " 'hard': 72,\n",
       " 'left': 73,\n",
       " 'political': 74,\n",
       " 'activists': 75,\n",
       " 'want': 76,\n",
       " 'censor': 77,\n",
       " 'challe…': 78,\n",
       " 'say': 79,\n",
       " 'delete': 80,\n",
       " 'use': 81,\n",
       " 'ini': 82,\n",
       " 'server': 83,\n",
       " 'after': 84,\n",
       " 'but': 85,\n",
       " 'lhfang': 86,\n",
       " 'hillary': 87,\n",
       " 'presidential': 88,\n",
       " 'nomination': 89,\n",
       " 'protesting': 90,\n",
       " 'campus': 91,\n",
       " 'speech…': 92,\n",
       " 'bhakti': 93,\n",
       " 'varak': 94,\n",
       " 'dear': 95,\n",
       " 'priyankac19': 96,\n",
       " 'officeofut': 97,\n",
       " 'ideology': 98,\n",
       " 'party': 99,\n",
       " 'shivsena': 100,\n",
       " 'stand': 101,\n",
       " 'workers': 102,\n",
       " 'openly…': 103,\n",
       " '90sgirl56': 104,\n",
       " 'aamir': 105,\n",
       " 'sir': 106,\n",
       " 'last': 107,\n",
       " '🥺': 108,\n",
       " 'villian': 109,\n",
       " 'never': 110,\n",
       " 'naam': 111,\n",
       " 'yaad': 112,\n",
       " 'rahega🥺🥺': 113,\n",
       " 'oversight': 114,\n",
       " 'board': 115,\n",
       " 'them': 116,\n",
       " 'against': 117,\n",
       " 'ireland': 118,\n",
       " 'campaign': 119,\n",
       " 'https': 120,\n",
       " 't': 121,\n",
       " 'co': 122,\n",
       " 'heersaleti': 123,\n",
       " '170': 124,\n",
       " 'farmers': 125,\n",
       " 'died': 126,\n",
       " 'no': 127,\n",
       " 'que': 128,\n",
       " 'done': 129,\n",
       " 'old': 130,\n",
       " 'something': 131,\n",
       " 'from': 132,\n",
       " 'aoc': 133,\n",
       " 'alexfeinberg1': 134,\n",
       " 'thought': 135,\n",
       " 'about': 136,\n",
       " 'protecting': 137,\n",
       " 'vulnerable': 138,\n",
       " \"didn't\": 139,\n",
       " 'pegobry': 140,\n",
       " 'did': 141,\n",
       " 'not': 142,\n",
       " 'squeezes': 143,\n",
       " 'declared': 144,\n",
       " 'my': 145,\n",
       " '2021': 146,\n",
       " 'bingo': 147,\n",
       " 'card': 148,\n",
       " 'official': 149,\n",
       " 'source': 150,\n",
       " 'wrong': 151,\n",
       " 'anyway': 152,\n",
       " 'should': 153,\n",
       " 'probably': 154,\n",
       " \"it's\": 155,\n",
       " 'at': 156,\n",
       " 'point': 157,\n",
       " 'unconstructive': 158,\n",
       " 'gracesm94145617': 159,\n",
       " 'rkymtniww': 160,\n",
       " 'laurenboebert': 161,\n",
       " 'well': 162,\n",
       " 'depends': 163,\n",
       " 'what': 164,\n",
       " 'free': 165,\n",
       " 'if': 166,\n",
       " 'commit': 167,\n",
       " 'act': 168,\n",
       " 'crime': 169,\n",
       " 'syahredzan': 170,\n",
       " 'alianisbgd': 171,\n",
       " 'yuliansahap': 172,\n",
       " 'bdsmovement': 173,\n",
       " 'asking': 174,\n",
       " 'add': 175,\n",
       " 'word': 176,\n",
       " '“zionist”': 177,\n",
       " 'its': 178,\n",
       " 'policy': 179,\n",
       " 'ismailsabri60': 180,\n",
       " 'ramai²': 181,\n",
       " 'progrockfarmer': 182,\n",
       " 'epstein': 183,\n",
       " 'killed': 184,\n",
       " 'himself': 185,\n",
       " 'spokesperson': 186,\n",
       " 'tells': 187,\n",
       " 'me': 188,\n",
       " 'clear': 189,\n",
       " 'quel': 190,\n",
       " 'discours': 191,\n",
       " 'haine': 192,\n",
       " 'rirryvlny': 193,\n",
       " 'kamu': 194,\n",
       " 'hobi': 195,\n",
       " 'menebar': 196,\n",
       " 'gt': 197,\n",
       " 'kalo': 198,\n",
       " 'gajadi': 199,\n",
       " 'buzzer': 200,\n",
       " 'politik': 201,\n",
       " 'ya': 202,\n",
       " 'rugi': 203,\n",
       " 'toh': 204,\n",
       " 'sebenere': 205,\n",
       " 'nbcnews': 206,\n",
       " 'posted': 207,\n",
       " 'hpmacd': 208,\n",
       " 'shutting': 209,\n",
       " 'down': 210,\n",
       " 'wsb': 211,\n",
       " '“hate': 212,\n",
       " 'speech”': 213,\n",
       " 'trading': 214,\n",
       " 'hours': 215,\n",
       " 'e': 216,\n",
       " 'when': 217,\n",
       " 'institutional': 218,\n",
       " 'investors': 219,\n",
       " 'huge': 220,\n",
       " 'advantage…': 221,\n",
       " 'ไม่สร้างความเกลียดชังเลย': 222,\n",
       " '55555': 223,\n",
       " 'เอาจริงๆถ้าจะให้ทำคอนเทนต์': 224,\n",
       " 'จริง': 225,\n",
       " 'กูทำได้ดีกว่ามึงเยอะ': 226,\n",
       " 'แต่สื่อเขาไม่ทำกันเพราะยังมีความเป็นคนอยู่ไง': 227,\n",
       " 'ไอ้สื่อลิ้มเลียหีปลาโลมา': 228,\n",
       " 'จาบจ้วงประชาชนเลียไข่พ่อมัน': 229,\n",
       " 'zeaxumawit': 230,\n",
       " 'how': 231,\n",
       " 'youtube': 232,\n",
       " 'clip': 233,\n",
       " 'daniel': 234,\n",
       " \"kibret's\": 235,\n",
       " 'still': 236,\n",
       " 'host': 237,\n",
       " 'full': 238,\n",
       " 'video': 239,\n",
       " 'adebabyme…': 240,\n",
       " '🤦🏾\\u200d♂️': 241,\n",
       " 'dailycaller': 242,\n",
       " 'reverses': 243,\n",
       " 'censorship': 244,\n",
       " 'allegedly': 245,\n",
       " 'labeling': 246,\n",
       " 'content': 247,\n",
       " '‘hate': 248,\n",
       " 'speech’': 249,\n",
       " '‘misinformatio…': 250,\n",
       " 'tina': 251,\n",
       " 'hokwana': 252,\n",
       " 'person': 253,\n",
       " 'anti': 254,\n",
       " 'homosexuality': 255,\n",
       " 'without': 256,\n",
       " 'discriminating': 257,\n",
       " 'their': 258,\n",
       " 'rights': 259,\n",
       " 'target': 260,\n",
       " 'on\\xa0platform': 261,\n",
       " 'qcwqc6kvao': 262,\n",
       " 'launches': 263,\n",
       " 'tackle': 264,\n",
       " 'their\\xa0platform': 265,\n",
       " 'nlytzewwap': 266,\n",
       " 'vlada': 267,\n",
       " 'janjanin': 268,\n",
       " 'uspehpetrovic': 269,\n",
       " 'jachim992': 270,\n",
       " 'pa': 271,\n",
       " 'ugasili': 272,\n",
       " 'su': 273,\n",
       " 'im': 274,\n",
       " 'liv': 275,\n",
       " 'boeree': 276,\n",
       " '“it': 277,\n",
       " 'change': 278,\n",
       " 'nothing”': 279,\n",
       " 'they': 280,\n",
       " 'said': 281,\n",
       " 'izzygirl86': 282,\n",
       " 'se': 283,\n",
       " 'podía': 284,\n",
       " 'saber': 285,\n",
       " 'el': 286,\n",
       " 'engendro': 287,\n",
       " 'del': 288,\n",
       " 'era': 289,\n",
       " 'más': 290,\n",
       " 'una': 291,\n",
       " 'herramienta': 292,\n",
       " 'control': 293,\n",
       " 'masas': 294,\n",
       " 'utilizar': 295,\n",
       " 'discreció…': 296,\n",
       " 'disgusting': 297,\n",
       " 'white': 298,\n",
       " 'hair': 299,\n",
       " 'man': 300,\n",
       " 'there': 301,\n",
       " 'trying': 302,\n",
       " 'banned': 303,\n",
       " '🤡🌍🤷\\u200d♂️': 304,\n",
       " 'husinshihab': 305,\n",
       " 'doakan': 306,\n",
       " 'semoga': 307,\n",
       " 'lancar': 308,\n",
       " 'hari': 309,\n",
       " 'kita': 310,\n",
       " 'sidang': 311,\n",
       " 'kasus': 312,\n",
       " 'syahganda': 313,\n",
       " 'salah': 314,\n",
       " 'satu': 315,\n",
       " 'deklarator': 316,\n",
       " 'kami': 317,\n",
       " 'terkait': 318,\n",
       " 'dugaan': 319,\n",
       " 'berita': 320,\n",
       " 'bohong': 321,\n",
       " 'dan': 322,\n",
       " 'hat…': 323,\n",
       " 'sedlaw15': 324,\n",
       " 'incredible': 325,\n",
       " 'language': 326,\n",
       " 'one': 327,\n",
       " 'decisions': 328,\n",
       " 'released': 329,\n",
       " \"facebook's\": 330,\n",
       " 'administration': 331,\n",
       " 'today': 332,\n",
       " 'cas…': 333,\n",
       " 'jack': 334,\n",
       " 'dorsie': 335,\n",
       " 'jugek': 336,\n",
       " 'ggreenwald': 337,\n",
       " 'template': 338,\n",
       " 'created': 339,\n",
       " 'demonize': 340,\n",
       " 'used': 341,\n",
       " 'supporters': 342,\n",
       " 'har…': 343,\n",
       " 'dividing': 344,\n",
       " 'america': 345,\n",
       " 'perspective': 346,\n",
       " '13': 347,\n",
       " 'year': 348,\n",
       " 'throwing': 349,\n",
       " 'temper': 350,\n",
       " 'tantrum': 351,\n",
       " 'enjoy': 352,\n",
       " 'like': 353,\n",
       " 'light': 354,\n",
       " 'while': 355,\n",
       " 'lasts': 356,\n",
       " 'wall': 357,\n",
       " 'st': 358,\n",
       " 'game': 359,\n",
       " 'stop': 360,\n",
       " 'going': 361,\n",
       " 'burn': 362,\n",
       " 'because': 363,\n",
       " 'pandemic': 364,\n",
       " 'so': 365,\n",
       " 'more': 366,\n",
       " 'than': 367,\n",
       " '130': 368,\n",
       " 'stock': 369}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(text)\n",
    "padded=pad_sequences(sequences,maxlen=max_length,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 138, 139,  25],\n",
       "       [  0,   0,   0, ...,  14,  15,  16],\n",
       "       [  0,   0,   0, ..., 146, 147, 148],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 355,  33, 356],\n",
       "       [  0,   0,   0, ...,  14,  15,  16],\n",
       "       [  0,   0,   0, ...,  19,   5, 369]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      RT @alexfeinberg1: You really thought \"Hate Sp...\n",
       "2      RT @PoliticalShort: Soon \"the market is rigged...\n",
       "3      RT @pegobry: I did not have \"Short squeezes ar...\n",
       "4                            Just report for hate speech\n",
       "5      RT @PoliticalShort: Soon \"the market is rigged...\n",
       "                             ...                        \n",
       "112    RT @PrisonPlanet: The #GameStop saga has taugh...\n",
       "113    RT @ggreenwald: This is the template created t...\n",
       "114    @AOC AOC your hate speech is dividing America ...\n",
       "115    RT @PoliticalShort: Soon \"the market is rigged...\n",
       "117    Wall St: \"Game Stop is going to burn because o...\n",
       "Name: text, Length: 78, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to find frequency of each word\n",
    "arr={}\n",
    "def frequen(str): \n",
    "    str = str.split()          \n",
    "    str2 = [] \n",
    "    # loop till string values present in list str \n",
    "    for i in str:              \n",
    "        # checking for the duplicacy \n",
    "        if i not in str2: \n",
    "        # insert value in str2 \n",
    "            str2.append(i)  \n",
    "              \n",
    "    for i in range(0, len(str2)): \n",
    "        print('Frequency of', str2[i], 'is :', str.count(str2[i])) \n",
    "        arr[str2[i]]=str.count(str2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6: expected 6 fields, saw 9\\nSkipping line 9: expected 6 fields, saw 7\\nSkipping line 25: expected 6 fields, saw 8\\nSkipping line 26: expected 6 fields, saw 7\\nSkipping line 34: expected 6 fields, saw 7\\nSkipping line 35: expected 6 fields, saw 7\\nSkipping line 37: expected 6 fields, saw 9\\nSkipping line 38: expected 6 fields, saw 9\\nSkipping line 39: expected 6 fields, saw 8\\nSkipping line 43: expected 6 fields, saw 7\\nSkipping line 58: expected 6 fields, saw 8\\nSkipping line 67: expected 6 fields, saw 9\\nSkipping line 68: expected 6 fields, saw 7\\nSkipping line 69: expected 6 fields, saw 8\\nSkipping line 70: expected 6 fields, saw 8\\nSkipping line 106: expected 6 fields, saw 10\\nSkipping line 109: expected 6 fields, saw 10\\nSkipping line 110: expected 6 fields, saw 7\\nSkipping line 122: expected 6 fields, saw 9\\nSkipping line 126: expected 6 fields, saw 7\\nSkipping line 133: expected 6 fields, saw 10\\nSkipping line 143: expected 6 fields, saw 8\\nSkipping line 146: expected 6 fields, saw 7\\nSkipping line 150: expected 6 fields, saw 7\\nSkipping line 160: expected 6 fields, saw 8\\nSkipping line 162: expected 6 fields, saw 7\\nSkipping line 164: expected 6 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('out.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=str(\"\")\n",
    "for i in string:\n",
    "    x=str(i)+str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of nannannannanWall is : 1\n",
      "Frequency of St: is : 1\n",
      "Frequency of \"Game is : 1\n",
      "Frequency of Stop is : 1\n",
      "Frequency of is is : 39\n",
      "Frequency of going is : 1\n",
      "Frequency of to is : 14\n",
      "Frequency of burn is : 1\n",
      "Frequency of because is : 1\n",
      "Frequency of of is : 10\n",
      "Frequency of the is : 17\n",
      "Frequency of pandemic is : 1\n",
      "Frequency of so is : 1\n",
      "Frequency of we is : 3\n",
      "Frequency of will is : 27\n",
      "Frequency of short is : 2\n",
      "Frequency of more is : 1\n",
      "Frequency of than is : 1\n",
      "Frequency of 130% is : 1\n",
      "Frequency of stock.\"nanRT is : 1\n",
      "Frequency of @PoliticalShort: is : 25\n",
      "Frequency of Soon is : 25\n",
      "Frequency of \"the is : 25\n",
      "Frequency of market is : 25\n",
      "Frequency of rigged\" is : 25\n",
      "Frequency of be is : 27\n",
      "Frequency of deemed is : 25\n",
      "Frequency of hate is : 46\n",
      "Frequency of speech is : 38\n",
      "Frequency of by is : 25\n",
      "Frequency of Big is : 25\n",
      "Frequency of Tech.@AOC is : 1\n",
      "Frequency of AOC is : 1\n",
      "Frequency of your is : 5\n",
      "Frequency of dividing is : 1\n",
      "Frequency of America is : 1\n",
      "Frequency of and is : 8\n",
      "Frequency of you is : 3\n",
      "Frequency of really is : 2\n",
      "Frequency of have is : 3\n",
      "Frequency of perspective is : 1\n",
      "Frequency of a is : 8\n",
      "Frequency of 13 is : 1\n",
      "Frequency of year is : 1\n",
      "Frequency of old is : 2\n",
      "Frequency of throwing is : 1\n",
      "Frequency of temper is : 1\n",
      "Frequency of tantrum. is : 1\n",
      "Frequency of Enjoy is : 1\n",
      "Frequency of like is : 1\n",
      "Frequency of light is : 1\n",
      "Frequency of while is : 1\n",
      "Frequency of it is : 4\n",
      "Frequency of lasts.RT is : 1\n",
      "Frequency of @ggreenwald: is : 1\n",
      "Frequency of This is : 3\n",
      "Frequency of template is : 1\n",
      "Frequency of created is : 1\n",
      "Frequency of demonize is : 1\n",
      "Frequency of silence is : 5\n",
      "Frequency of anyone is : 3\n",
      "Frequency of challenging is : 3\n",
      "Frequency of elites. is : 1\n",
      "Frequency of It is : 1\n",
      "Frequency of was is : 2\n",
      "Frequency of used is : 1\n",
      "Frequency of against is : 2\n",
      "Frequency of Bernie is : 3\n",
      "Frequency of supporters is : 1\n",
      "Frequency of (\"har…RT is : 1\n",
      "Frequency of @PrisonPlanet: is : 4\n",
      "Frequency of The is : 4\n",
      "Frequency of #GameStop is : 4\n",
      "Frequency of saga is : 4\n",
      "Frequency of has is : 5\n",
      "Frequency of taught is : 4\n",
      "Frequency of us is : 4\n",
      "Frequency of that is : 5\n",
      "Frequency of \"hate is : 5\n",
      "Frequency of speech\" is : 6\n",
      "Frequency of just is : 5\n",
      "Frequency of an is : 5\n",
      "Frequency of excuse is : 4\n",
      "Frequency of for is : 13\n",
      "Frequency of technocratic is : 4\n",
      "Frequency of elites is : 4\n",
      "Frequency of &amp; is : 4\n",
      "Frequency of blockade is : 4\n",
      "Frequency of their…Done is : 1\n",
      "Frequency of report is : 5\n",
      "Frequency of jugeknannan# is : 1\n",
      "Frequency of Jack is : 1\n",
      "Frequency of DorsieRT is : 1\n",
      "Frequency of @SEDLAW15: is : 1\n",
      "Frequency of incredible is : 1\n",
      "Frequency of language is : 1\n",
      "Frequency of from is : 2\n",
      "Frequency of one is : 1\n",
      "Frequency of decisions is : 1\n",
      "Frequency of released is : 1\n",
      "Frequency of Facebook's is : 1\n",
      "Frequency of Oversight is : 2\n",
      "Frequency of Administration is : 1\n",
      "Frequency of Board is : 2\n",
      "Frequency of today. is : 1\n",
      "Frequency of cas…RT is : 1\n",
      "Frequency of @HusinShihab: is : 1\n",
      "Frequency of Doakan is : 1\n",
      "Frequency of semoga is : 1\n",
      "Frequency of lancar is : 1\n",
      "Frequency of hari is : 1\n",
      "Frequency of ini is : 1\n",
      "Frequency of kita is : 1\n",
      "Frequency of sidang is : 1\n",
      "Frequency of kasus is : 1\n",
      "Frequency of @syahganda is : 1\n",
      "Frequency of salah is : 1\n",
      "Frequency of satu is : 1\n",
      "Frequency of deklarator is : 1\n",
      "Frequency of KAMI is : 1\n",
      "Frequency of terkait is : 1\n",
      "Frequency of dugaan is : 1\n",
      "Frequency of berita is : 1\n",
      "Frequency of bohong is : 1\n",
      "Frequency of dan is : 1\n",
      "Frequency of hat…RT is : 1\n",
      "Frequency of @lhfang: is : 2\n",
      "Frequency of Hillary is : 2\n",
      "Frequency of presidential is : 2\n",
      "Frequency of nomination? is : 2\n",
      "Frequency of That's is : 4\n",
      "Frequency of speech. is : 3\n",
      "Frequency of Protesting is : 2\n",
      "Frequency of Israel is : 3\n",
      "Frequency of on is : 6\n",
      "Frequency of campus? is : 2\n",
      "Frequency of speech…RT is : 2\n",
      "Frequency of Tech.There is : 1\n",
      "Frequency of trying is : 1\n",
      "Frequency of but is : 2\n",
      "Frequency of something is : 2\n",
      "Frequency of them is : 2\n",
      "Frequency of banned....🤡🌍🤷‍♂️RT is : 1\n",
      "Frequency of Tech.RT is : 9\n",
      "Frequency of Tech.nannannanRT is : 2\n",
      "Frequency of @HeerSaleti_: is : 2\n",
      "Frequency of -170+ is : 2\n",
      "Frequency of farmers is : 2\n",
      "Frequency of diedRT is : 2\n",
      "Frequency of Tech.Done is : 1\n",
      "Frequency of Disgusting is : 1\n",
      "Frequency of white is : 1\n",
      "Frequency of hair is : 1\n",
      "Frequency of man.RT is : 1\n",
      "Frequency of @LozzaFox: is : 2\n",
      "Frequency of \"The is : 2\n",
      "Frequency of people is : 2\n",
      "Frequency of Duke is : 2\n",
      "Frequency of Duchess is : 2\n",
      "Frequency of Sussex is : 2\n",
      "Frequency of are is : 5\n",
      "Frequency of funding is : 2\n",
      "Frequency of hard-left is : 2\n",
      "Frequency of political is : 2\n",
      "Frequency of activists is : 2\n",
      "Frequency of who is : 4\n",
      "Frequency of want is : 2\n",
      "Frequency of censor is : 2\n",
      "Frequency of challe…RT is : 2\n",
      "Frequency of @izzygirl86: is : 1\n",
      "Frequency of No is : 1\n",
      "Frequency of se is : 1\n",
      "Frequency of podía is : 1\n",
      "Frequency of saber is : 1\n",
      "Frequency of que is : 2\n",
      "Frequency of el is : 1\n",
      "Frequency of engendro is : 1\n",
      "Frequency of del is : 1\n",
      "Frequency of no is : 1\n",
      "Frequency of era is : 1\n",
      "Frequency of más is : 1\n",
      "Frequency of una is : 1\n",
      "Frequency of herramienta is : 1\n",
      "Frequency of de is : 3\n",
      "Frequency of control is : 1\n",
      "Frequency of masas is : 1\n",
      "Frequency of utilizar is : 1\n",
      "Frequency of discreció…nanRT is : 1\n",
      "Frequency of @Liv_Boeree: is : 1\n",
      "Frequency of “it is : 1\n",
      "Frequency of change is : 1\n",
      "Frequency of nothing” is : 1\n",
      "Frequency of they is : 1\n",
      "Frequency of saidRT is : 1\n",
      "Frequency of Tech.nannan@vlada_janjanin is : 1\n",
      "Frequency of @UspehPetrovic is : 1\n",
      "Frequency of @Jachim992 is : 1\n",
      "Frequency of Pa...ugasili is : 1\n",
      "Frequency of su is : 1\n",
      "Frequency of im is : 1\n",
      "Frequency of discord is : 1\n",
      "Frequency of server is : 2\n",
      "Frequency of RT is : 2\n",
      "Frequency of their…nanRT is : 1\n",
      "Frequency of @wokal_distance: is : 4\n",
      "Frequency of 1/RT is : 2\n",
      "Frequency of Tech.Facebook is : 2\n",
      "Frequency of Ireland is : 2\n",
      "Frequency of launches is : 1\n",
      "Frequency of campaign is : 2\n",
      "Frequency of tackle is : 1\n",
      "Frequency of their is : 2\n",
      "Frequency of platform is : 2\n",
      "Frequency of https://t.co/nLyTzEwWAPRT is : 1\n",
      "Frequency of target is : 1\n",
      "Frequency of https://t.co/qCWQc6kvAORT is : 1\n",
      "Frequency of Tech.nanRT is : 3\n",
      "Frequency of @90sgirl56: is : 2\n",
      "Frequency of Aamir is : 2\n",
      "Frequency of sir is : 2\n",
      "Frequency of last is : 2\n",
      "Frequency of 🥺 is : 2\n",
      "Frequency of Zafar is : 4\n",
      "Frequency of villian is : 2\n",
      "Frequency of can is : 2\n",
      "Frequency of never is : 2\n",
      "Frequency of naam is : 2\n",
      "Frequency of yaad is : 2\n",
      "Frequency of rahega🥺🥺 is : 2\n",
      "Frequency of nannan@Tina_Hokwana is : 1\n",
      "Frequency of Can is : 1\n",
      "Frequency of person is : 1\n",
      "Frequency of anti is : 1\n",
      "Frequency of homosexuality is : 1\n",
      "Frequency of without is : 1\n",
      "Frequency of discriminating is : 1\n",
      "Frequency of rights?RT is : 1\n",
      "Frequency of @DailyCaller: is : 1\n",
      "Frequency of REPORT: is : 1\n",
      "Frequency of For is : 1\n",
      "Frequency of Facebook is : 1\n",
      "Frequency of Reverses is : 1\n",
      "Frequency of Censorship is : 1\n",
      "Frequency of After is : 1\n",
      "Frequency of Allegedly is : 1\n",
      "Frequency of Labeling is : 1\n",
      "Frequency of Content is : 1\n",
      "Frequency of ‘Hate is : 1\n",
      "Frequency of Speech’ is : 1\n",
      "Frequency of And is : 1\n",
      "Frequency of ‘Misinformatio…nanRT is : 1\n",
      "Frequency of 1/nanRT is : 1\n",
      "Frequency of nannanRT is : 1\n",
      "Frequency of @Bhakti_Varak: is : 2\n",
      "Frequency of Dear is : 2\n",
      "Frequency of @priyankac19 is : 2\n",
      "Frequency of @OfficeofUT is : 2\n",
      "Frequency of this is : 4\n",
      "Frequency of ideology is : 2\n",
      "Frequency of party is : 2\n",
      "Frequency of @ShivSena is : 2\n",
      "Frequency of does is : 3\n",
      "Frequency of stand is : 2\n",
      "Frequency of workers is : 2\n",
      "Frequency of openly…nannanRT is : 1\n",
      "Frequency of openly…nannan🤦🏾‍♂️RT is : 1\n",
      "Frequency of @zeaxumawit: is : 1\n",
      "Frequency of How is : 1\n",
      "Frequency of @YouTube is : 1\n",
      "Frequency of delete is : 1\n",
      "Frequency of clip is : 1\n",
      "Frequency of Daniel is : 1\n",
      "Frequency of Kibret's is : 1\n",
      "Frequency of still is : 1\n",
      "Frequency of host is : 1\n",
      "Frequency of full is : 1\n",
      "Frequency of video is : 1\n",
      "Frequency of @adebabyMe…nannanRT is : 1\n",
      "Frequency of their…RT is : 1\n",
      "Frequency of Tech.nanไม่สร้างความเกลียดชังเลย is : 1\n",
      "Frequency of 55555 is : 1\n",
      "Frequency of เอาจริงๆถ้าจะให้ทำคอนเทนต์ is : 1\n",
      "Frequency of Hate is : 1\n",
      "Frequency of Speech is : 1\n",
      "Frequency of จริง is : 1\n",
      "Frequency of กูทำได้ดีกว่ามึงเยอะ is : 1\n",
      "Frequency of แต่สื่อเขาไม่ทำกันเพราะยังมีความเป็นคนอยู่ไง is : 1\n",
      "Frequency of ไอ้สื่อลิ้มเลียหีปลาโลมา is : 1\n",
      "Frequency of จาบจ้วงประชาชนเลียไข่พ่อมันRT is : 1\n",
      "Frequency of @hpmacd: is : 1\n",
      "Frequency of Discord is : 2\n",
      "Frequency of shutting is : 1\n",
      "Frequency of down is : 1\n",
      "Frequency of WSB is : 1\n",
      "Frequency of “hate is : 1\n",
      "Frequency of speech” is : 1\n",
      "Frequency of after is : 1\n",
      "Frequency of trading is : 1\n",
      "Frequency of hours is : 1\n",
      "Frequency of (i.e. is : 1\n",
      "Frequency of when is : 1\n",
      "Frequency of institutional is : 1\n",
      "Frequency of investors is : 1\n",
      "Frequency of huge is : 1\n",
      "Frequency of advantage…nan@NBCNews is : 1\n",
      "Frequency of Posted... is : 1\n",
      "Frequency of @RirryVLNY: is : 1\n",
      "Frequency of kamu is : 1\n",
      "Frequency of hobi is : 1\n",
      "Frequency of menebar is : 1\n",
      "Frequency of gt is : 1\n",
      "Frequency of kalo is : 1\n",
      "Frequency of gajadi is : 1\n",
      "Frequency of buzzer is : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of politik is : 1\n",
      "Frequency of ya is : 1\n",
      "Frequency of rugi is : 1\n",
      "Frequency of toh is : 1\n",
      "Frequency of sebenereRT is : 1\n",
      "Frequency of Tech.nanQuel is : 1\n",
      "Frequency of discours is : 1\n",
      "Frequency of haine is : 1\n",
      "Frequency of ? is : 1\n",
      "Frequency of spokesperson is : 1\n",
      "Frequency of tells is : 1\n",
      "Frequency of me. is : 1\n",
      "Frequency of \"To is : 1\n",
      "Frequency of clearnanRT is : 1\n",
      "Frequency of @Progrockfarmer: is : 1\n",
      "Frequency of \"Epstein is : 1\n",
      "Frequency of killed is : 1\n",
      "Frequency of himself\"RT is : 1\n",
      "Frequency of Tech.@IsmailSabri60 is : 1\n",
      "Frequency of Ramai² is : 1\n",
      "Frequency of speech.nanRT is : 1\n",
      "Frequency of @BDSmovement: is : 1\n",
      "Frequency of asking is : 1\n",
      "Frequency of @Facebook is : 1\n",
      "Frequency of add is : 1\n",
      "Frequency of word is : 1\n",
      "Frequency of “Zionist” is : 1\n",
      "Frequency of its is : 1\n",
      "Frequency of policy.nannannanRT is : 1\n",
      "Frequency of 1/@AlianisBgd is : 1\n",
      "Frequency of @yuliansahap is : 1\n",
      "Frequency of Ini is : 1\n",
      "Frequency of hate.speechRT is : 1\n",
      "Frequency of @syahredzan: is : 1\n",
      "Frequency of Just is : 1\n",
      "Frequency of speechRT is : 2\n",
      "Frequency of Tech.nan@GraceSm94145617 is : 1\n",
      "Frequency of @rkymtniww is : 1\n",
      "Frequency of @laurenboebert is : 1\n",
      "Frequency of Well is : 1\n",
      "Frequency of depends is : 1\n",
      "Frequency of what is : 1\n",
      "Frequency of use is : 2\n",
      "Frequency of free is : 1\n",
      "Frequency of say. is : 1\n",
      "Frequency of If is : 1\n",
      "Frequency of commit is : 1\n",
      "Frequency of act is : 1\n",
      "Frequency of crimeRT is : 1\n",
      "Frequency of their…nannananyway.. is : 1\n",
      "Frequency of I is : 2\n",
      "Frequency of should is : 1\n",
      "Frequency of probably is : 1\n",
      "Frequency of delete.. is : 1\n",
      "Frequency of it's is : 1\n",
      "Frequency of at is : 1\n",
      "Frequency of point.. is : 1\n",
      "Frequency of unconstructive.. is : 1\n",
      "Frequency of nanOfficial is : 1\n",
      "Frequency of source is : 1\n",
      "Frequency of say is : 1\n",
      "Frequency of wrong.RT is : 1\n",
      "Frequency of Tech.Just is : 1\n",
      "Frequency of @pegobry: is : 1\n",
      "Frequency of did is : 1\n",
      "Frequency of not is : 1\n",
      "Frequency of \"Short is : 1\n",
      "Frequency of squeezes is : 1\n",
      "Frequency of declared is : 1\n",
      "Frequency of my is : 1\n",
      "Frequency of 2021 is : 1\n",
      "Frequency of bingo is : 1\n",
      "Frequency of card.RT is : 1\n",
      "Frequency of @alexfeinberg1: is : 1\n",
      "Frequency of You is : 1\n",
      "Frequency of thought is : 1\n",
      "Frequency of \"Hate is : 1\n",
      "Frequency of Speech\" is : 1\n",
      "Frequency of about is : 1\n",
      "Frequency of protecting is : 1\n",
      "Frequency of vulnerable is : 1\n",
      "Frequency of didn't is : 1\n",
      "Frequency of you? is : 1\n"
     ]
    }
   ],
   "source": [
    "frequen(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_items([('nannannannanWall', 1), ('St:', 1), ('\"Game', 1), ('Stop', 1), ('going', 1), ('burn', 1), ('because', 1), ('pandemic', 1), ('so', 1), ('more', 1), ('than', 1), ('130%', 1), ('stock.\"nanRT', 1), ('Tech.@AOC', 1), ('AOC', 1), ('dividing', 1), ('America', 1), ('perspective', 1), ('13', 1), ('year', 1), ('throwing', 1), ('temper', 1), ('tantrum.', 1), ('Enjoy', 1), ('like', 1), ('light', 1), ('while', 1), ('lasts.RT', 1), ('@ggreenwald:', 1), ('template', 1), ('created', 1), ('demonize', 1), ('elites.', 1), ('It', 1), ('used', 1), ('supporters', 1), ('(\"har…RT', 1), ('their…Done', 1), ('jugeknannan#', 1), ('Jack', 1), ('DorsieRT', 1), ('@SEDLAW15:', 1), ('incredible', 1), ('language', 1), ('one', 1), ('decisions', 1), ('released', 1), (\"Facebook's\", 1), ('Administration', 1), ('today.', 1), ('cas…RT', 1), ('@HusinShihab:', 1), ('Doakan', 1), ('semoga', 1), ('lancar', 1), ('hari', 1), ('ini', 1), ('kita', 1), ('sidang', 1), ('kasus', 1), ('@syahganda', 1), ('salah', 1), ('satu', 1), ('deklarator', 1), ('KAMI', 1), ('terkait', 1), ('dugaan', 1), ('berita', 1), ('bohong', 1), ('dan', 1), ('hat…RT', 1), ('Tech.There', 1), ('trying', 1), ('banned....🤡🌍🤷\\u200d♂️RT', 1), ('Tech.Done', 1), ('Disgusting', 1), ('white', 1), ('hair', 1), ('man.RT', 1), ('@izzygirl86:', 1), ('No', 1), ('se', 1), ('podía', 1), ('saber', 1), ('el', 1), ('engendro', 1), ('del', 1), ('no', 1), ('era', 1), ('más', 1), ('una', 1), ('herramienta', 1), ('control', 1), ('masas', 1), ('utilizar', 1), ('discreció…nanRT', 1), ('@Liv_Boeree:', 1), ('“it', 1), ('change', 1), ('nothing”', 1), ('they', 1), ('saidRT', 1), ('Tech.nannan@vlada_janjanin', 1), ('@UspehPetrovic', 1), ('@Jachim992', 1), ('Pa...ugasili', 1), ('su', 1), ('im', 1), ('discord', 1), ('their…nanRT', 1), ('launches', 1), ('tackle', 1), ('https://t.co/nLyTzEwWAPRT', 1), ('target', 1), ('https://t.co/qCWQc6kvAORT', 1), ('nannan@Tina_Hokwana', 1), ('Can', 1), ('person', 1), ('anti', 1), ('homosexuality', 1), ('without', 1), ('discriminating', 1), ('rights?RT', 1), ('@DailyCaller:', 1), ('REPORT:', 1), ('For', 1), ('Facebook', 1), ('Reverses', 1), ('Censorship', 1), ('After', 1), ('Allegedly', 1), ('Labeling', 1), ('Content', 1), ('‘Hate', 1), ('Speech’', 1), ('And', 1), ('‘Misinformatio…nanRT', 1), ('1/nanRT', 1), ('nannanRT', 1), ('openly…nannanRT', 1), ('openly…nannan🤦🏾\\u200d♂️RT', 1), ('@zeaxumawit:', 1), ('How', 1), ('@YouTube', 1), ('delete', 1), ('clip', 1), ('Daniel', 1), (\"Kibret's\", 1), ('still', 1), ('host', 1), ('full', 1), ('video', 1), ('@adebabyMe…nannanRT', 1), ('their…RT', 1), ('Tech.nanไม่สร้างความเกลียดชังเลย', 1), ('55555', 1), ('เอาจริงๆถ้าจะให้ทำคอนเทนต์', 1), ('Hate', 1), ('Speech', 1), ('จริง', 1), ('กูทำได้ดีกว่ามึงเยอะ', 1), ('แต่สื่อเขาไม่ทำกันเพราะยังมีความเป็นคนอยู่ไง', 1), ('ไอ้สื่อลิ้มเลียหีปลาโลมา', 1), ('จาบจ้วงประชาชนเลียไข่พ่อมันRT', 1), ('@hpmacd:', 1), ('shutting', 1), ('down', 1), ('WSB', 1), ('“hate', 1), ('speech”', 1), ('after', 1), ('trading', 1), ('hours', 1), ('(i.e.', 1), ('when', 1), ('institutional', 1), ('investors', 1), ('huge', 1), ('advantage…nan@NBCNews', 1), ('Posted...', 1), ('@RirryVLNY:', 1), ('kamu', 1), ('hobi', 1), ('menebar', 1), ('gt', 1), ('kalo', 1), ('gajadi', 1), ('buzzer', 1), ('politik', 1), ('ya', 1), ('rugi', 1), ('toh', 1), ('sebenereRT', 1), ('Tech.nanQuel', 1), ('discours', 1), ('haine', 1), ('?', 1), ('spokesperson', 1), ('tells', 1), ('me.', 1), ('\"To', 1), ('clearnanRT', 1), ('@Progrockfarmer:', 1), ('\"Epstein', 1), ('killed', 1), ('himself\"RT', 1), ('Tech.@IsmailSabri60', 1), ('Ramai²', 1), ('speech.nanRT', 1), ('@BDSmovement:', 1), ('asking', 1), ('@Facebook', 1), ('add', 1), ('word', 1), ('“Zionist”', 1), ('its', 1), ('policy.nannannanRT', 1), ('1/@AlianisBgd', 1), ('@yuliansahap', 1), ('Ini', 1), ('hate.speechRT', 1), ('@syahredzan:', 1), ('Just', 1), ('Tech.nan@GraceSm94145617', 1), ('@rkymtniww', 1), ('@laurenboebert', 1), ('Well', 1), ('depends', 1), ('what', 1), ('free', 1), ('say.', 1), ('If', 1), ('commit', 1), ('act', 1), ('crimeRT', 1), ('their…nannananyway..', 1), ('should', 1), ('probably', 1), ('delete..', 1), (\"it's\", 1), ('at', 1), ('point..', 1), ('unconstructive..', 1), ('nanOfficial', 1), ('source', 1), ('say', 1), ('wrong.RT', 1), ('Tech.Just', 1), ('@pegobry:', 1), ('did', 1), ('not', 1), ('\"Short', 1), ('squeezes', 1), ('declared', 1), ('my', 1), ('2021', 1), ('bingo', 1), ('card.RT', 1), ('@alexfeinberg1:', 1), ('You', 1), ('thought', 1), ('\"Hate', 1), ('Speech\"', 1), ('about', 1), ('protecting', 1), ('vulnerable', 1), (\"didn't\", 1), ('you?', 1), ('short', 2), ('really', 2), ('old', 2), ('was', 2), ('against', 2), ('from', 2), ('Oversight', 2), ('Board', 2), ('@lhfang:', 2), ('Hillary', 2), ('presidential', 2), ('nomination?', 2), ('Protesting', 2), ('campus?', 2), ('speech…RT', 2), ('but', 2), ('something', 2), ('them', 2), ('Tech.nannannanRT', 2), ('@HeerSaleti_:', 2), ('-170+', 2), ('farmers', 2), ('diedRT', 2), ('@LozzaFox:', 2), ('\"The', 2), ('people', 2), ('Duke', 2), ('Duchess', 2), ('Sussex', 2), ('funding', 2), ('hard-left', 2), ('political', 2), ('activists', 2), ('want', 2), ('censor', 2), ('challe…RT', 2), ('que', 2), ('server', 2), ('RT', 2), ('1/RT', 2), ('Tech.Facebook', 2), ('Ireland', 2), ('campaign', 2), ('their', 2), ('platform', 2), ('@90sgirl56:', 2), ('Aamir', 2), ('sir', 2), ('last', 2), ('🥺', 2), ('villian', 2), ('can', 2), ('never', 2), ('naam', 2), ('yaad', 2), ('rahega🥺🥺', 2), ('@Bhakti_Varak:', 2), ('Dear', 2), ('@priyankac19', 2), ('@OfficeofUT', 2), ('ideology', 2), ('party', 2), ('@ShivSena', 2), ('stand', 2), ('workers', 2), ('Discord', 2), ('speechRT', 2), ('use', 2), ('I', 2), ('we', 3), ('you', 3), ('have', 3), ('This', 3), ('anyone', 3), ('challenging', 3), ('Bernie', 3), ('speech.', 3), ('Israel', 3), ('de', 3), ('Tech.nanRT', 3), ('does', 3), ('it', 4), ('@PrisonPlanet:', 4), ('The', 4), ('#GameStop', 4), ('saga', 4), ('taught', 4), ('us', 4), ('excuse', 4), ('technocratic', 4), ('elites', 4), ('&amp;', 4), ('blockade', 4), (\"That's\", 4), ('who', 4), ('@wokal_distance:', 4), ('Zafar', 4), ('this', 4), ('your', 5), ('silence', 5), ('has', 5), ('that', 5), ('\"hate', 5), ('just', 5), ('an', 5), ('report', 5), ('are', 5), ('speech\"', 6), ('on', 6), ('and', 8), ('a', 8), ('Tech.RT', 9), ('of', 10), ('for', 13), ('to', 14), ('the', 17), ('@PoliticalShort:', 25), ('Soon', 25), ('\"the', 25), ('market', 25), ('rigged\"', 25), ('deemed', 25), ('by', 25), ('Big', 25), ('will', 27), ('be', 27), ('speech', 38), ('is', 39), ('hate', 46)])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "sortdict=OrderedDict(sorted(arr.items(), key=lambda t: t[1]))\n",
    "print(sortdict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortdict2=list(sortdict.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate\n",
      "is\n",
      "speech\n",
      "be\n",
      "will\n",
      "Big\n",
      "by\n",
      "deemed\n",
      "rigged\"\n",
      "market\n"
     ]
    }
   ],
   "source": [
    "for x in list(reversed(list(sortdict)))[0:10]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('market', 25),\n",
       " ('rigged\"', 25),\n",
       " ('deemed', 25),\n",
       " ('by', 25),\n",
       " ('Big', 25),\n",
       " ('will', 27),\n",
       " ('be', 27),\n",
       " ('speech', 38),\n",
       " ('is', 39),\n",
       " ('hate', 46)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortdict2[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
